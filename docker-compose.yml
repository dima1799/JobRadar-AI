
services:
  postgres:
    image: postgres:13
    container_name: airflow-postgres
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_db:/var/lib/postgresql/data

  airflow-webserver:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: airflow-webserver
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: mysecretkey
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - ./models:/opt/airflow/models
      - ./qdrant_storage:/opt/airflow/qdrant_storage
      - ./hf_cache:/opt/airflow/hf_cache
    command:
      webserver

  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: airflow-scheduler
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - ./models:/opt/airflow/models
      - ./qdrant_storage:/opt/airflow/qdrant_storage
      - ./hf_cache:/opt/airflow/hf_cache
    command:
      scheduler

  airflow-init:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: airflow-init
    depends_on:
      - postgres
    entrypoint: >
      bash -c "
      airflow db migrate &&
      airflow users create --username admin --firstname Air --lastname Flow --role Admin --email admin@example.org --password admin
      "
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./app:/opt/airflow/app
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - ./models:/opt/airflow/models
      - ./qdrant_storage:/opt/airflow/qdrant_storage
      - ./hf_cache:/opt/airflow/hf_cache


  qdrant:
    image: qdrant/qdrant:latest
    restart: always
    volumes:
      - ./qdrant_storage:/qdrant/storage
    ports:
      - "6333:6333"

  bot:
    build: .
    network_mode: host
    container_name: jobradar-ai-bot
    restart: no
    working_dir: /app
    volumes:
      - .:/app                      # код проекта
      - ./hf_cache:/root/.cache/huggingface   # кэш моделей HF (сохраняется между запусками)
      - ./models:/models
    depends_on:
      - qdrant
    env_file: .env
    environment:
      # переменные моделей
      EMBED_MODEL: "${EMBED_MODEL:-deepvk/USER-bge-m3}"
      TRANSFORMERS_CACHE: "/root/.cache/huggingface"
      HF_HOME: "/root/.cache/huggingface"
      MODEL_DIR: "/models/USER-bge-m3"  # <— укажем локальный путь
      # важное: локальные адреса не через прокси
      NO_PROXY: "127.0.0.1,localhost,qdrant,85.208.208.39,huggingface.co,cdn-lfs.huggingface.co"
      # конфиг приложения
      QDRANT_URL: "http://qdrant:6333"                 # напр. http://qdrant:6333 или http://127.0.0.1:6333
      QDRANT_COLLECTION: "${QDRANT_COLLECTION:-vacancies}"
      TELEGRAM_BOT_TOKEN: "${TELEGRAM_BOT_TOKEN}"
      TOGETHER_API_KEY: "${TOGETHER_API_KEY}"

volumes:
  postgres_db:
